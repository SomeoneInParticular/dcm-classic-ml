# Results Interpretation

## Running `result_analysis.ipynb`

1. Install Pandas, Seaborn, and Matplotlib, if you have not already done so
2. Run the full analysis as described in `classic_ml_reloaded/README.md` on a valid BIDS dataset. 
   * The notebook assumes the resulting database is named `results.db`, and is placed in the directory above this one (where our study generated it). If your output not here, either move it here or edit the `result_analysis.ipynb` to load from your location prior to step 4.
3. Install and run Jupyter Notebook or Jupyter Lab within this directory (see [here](https://docs.jupyter.org/en/latest/install.html) for how to do this)
4. Run all cells in `result_analysis.ipynb`; this can take a few minutes as there are a large number of plots being generated (all of which are saved in the `figures/` directory).

## Result filtering

As the study design is a 10-replicate, 10-fold, 100-trial one, any studies which did not complete the full 10,000 trials were dropped. Currently, this only really includes some of the PCA -> RFE pre-processing code (as RFE raises an error if only one principal component is generated by the PCA post-tuning), but 15 ran to completion regardless. This, in total, resulted in 155 completed study replicates at present.

# Metric Distributions

All metrics were based on our study's dataset; if you are running this on a different dataset, the results are almost certain to change!

## mJOA

## Pre-Surgery

Distribution was roughly normal, with the largest proportion of patients (131/292) having moderate severity DCM prior to surgical treatment. Once the notebook has been run, a histogram plot of this can be found at `figures/mjoa_dist/pre_treatment_mjoa.svg`.

## Post-Surgery

As would be expected, the average mJOA score post-surgery was substantially better, with the majority of patients (163/292) now having mild DCM after surgical treatment. Once the notebook has been run, a histogram plot of this can be found at `figures/mjoa_dist/post_treatment_mjoa.svg`.

## Improvement Distributions

Likewise, the majority of patients (214/292) saw some improvement in their condition (defined as their post-surgical mJOA exceeding their pre-surgical mJOA by any amount), as shown below. Once the notebook has been run, a histogram plot of this can be found at `figures/mjoa_dist/treatment_mjoa_delta.svg`.

However, whether patients saw significant improvement in their condition (as defined by a Hirabayashi Recovery Ratio (HRR) of 0.5 of greater, see figure below), the majority is much closer, with only 53% of patients doing so. The Kernel Density Estimates of this metric, stratified by the DCM severity of the patient pre-surgery, can be found at `figures/mjoa_dist/hirabayashi_ratios.svg` after the notebook has been run.

## Demographics

### Age

As would be expected, the vast majority of patients in this study were older than 40. A histogram of the overall distribution can be found at `figures/demo_dist/age_dist.svg` after the notebook has been run.

### Sex

The majority of patients (60.62%) were male, with all others being female. A pie chart of the ratio can be found at `figures/demo_dist/sex_dist.svg` after the notebook has been run.

### Body Mass Index (BMI)

Most patients had a BMI equal to or greater than 25, which indicates they were overweight or obese. A histogram of the overall distribution can be found at `figures/demo_dist/bmi_dist.svg` after the notebook has been run.

### Symptom Duration

Most (63.71%) of the patients in our dataset had symptoms for more than 2 years before receiving surgical treatment. A pie chart of the ratio can be found at `figures/demo_dist/symptom_duration_dist.svg` after the notebook has been run.

### Work status

Most patients were either actively working (labelled as `W`) or were retired, self-employed, or working-from-home (together labelled as `HSR`). Only 21.58% of patients in our dataset were not actively employed or retired in some form. A pie chart of the ratio can be found at `figures/demo_dist/work_status_(category)_dist.svg` after the notebook has been run.

# Performance by Trial

## Balanced Accuracy

The graphs placed within `figures/bacc_performance` were designed to help tease out any trends in performance across Optuna trials for various analytical protocols in the study. These plots are stratified in two major ways

1. Protocol Variant
   * `dataset`: Plot stratified by what set of features were used during model training 
     * `img`: Imaging only
     * `clinical`: Clinical metrics only
     * `full`: Both clinical and imaging metrics used
   * `ori`: The orientation of the imaging metrics used, if they were used.
     * `axial`: Axially-oriented MRI sequences.
     * `sag`: Sagittally-oriented MRI sequences.
     * `none`: No imaging metrics used (clinical-only)
     * **NOTE:** For our purposes, 3d images are marked as `axial` as, in our dataset, the handful of 3d images we had had a higher axial resolution than sagittal.
   * `weight`: The imaging weight (or contrast) used
     * `T1w`: T1-weighted (high contrast between fatty and hydrous tissue)
     * `T2w`: T2-weighted (high contrast liquids and solid mass)
     * `none`: No imaging metrics used (clinical-only)
   * `model`: The Machine-Learning model being tested
     * `AdaBoostClassifier`: AdaBoosted Classifiers, each composed of a tuned chain of Decision Trees with tuned parameters.
     * `RandomForestClassifier`: Random Forest Classifiers, each consisting of a tuned bundle of Decision Trees with tuned parameters.
     * `KNNC`: K-Nearest Neighbor Classifiers, tested with various numbers of neighbors and regularization.
     * `SupportVectorClassifier`: Support Vector Machines, tested with various kernels.
     * `LogisticRegression`: Logistic Regressions, testing with various forms and degrees of regularization. 
2. Metric Assessed
   * `avg`: The average _performance value at testing_ across all replicates and analytical permutations which matched the criterion above, with error bounds of +/- 1 standard deviation.
   * `avg`: The same as prior, except how much a given trial's value contributes to the mean is weighted by its _performance value at validation_. This helps supress high testing performance samples which occur by chance (when validation performance is low).  
   * `max`: The peak performance observed in each set of analytical permutations which matched the criterion above, averaged with error bounds of +/- 1 standard deviation (each calculated across replicates).
   * `test_at_peak_validate`: The _testing_ performance of each analytical permutation which matched the criterion above, sampled from the protocol with the best _validation_ performance. This is averaged with error bounds of +/- 1 standard deviation (each calculated across replicates), and aims to evaluate how well a model's performance during evaluation would transfer to its performance on data it has never seen before.
     * **NOTE:** Due to many of our models overfitting during train-validation tuning (reaching exactly 100% balance accuracy), this is measure should be considered incomplete due to ties in performance being broken randomly.
