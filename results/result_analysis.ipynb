{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf01c257-225d-4646-9315-3129cf3a99a0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199ddb1-292a-4a7c-b7a0-0b6174d3cfa0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5052fd7-31a0-44eb-873c-fde1985b7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, permutations\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlite3 import connect\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(707260)\n",
    "\n",
    "skip_plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d8e32-1da6-4701-b5f3-b051f782483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_source = 'results.db'\n",
    "con = connect(db_source)\n",
    "tables = pd.read_sql(\n",
    "    \"SELECT * FROM sqlite_master\", \n",
    "    con=con\n",
    ").loc[:, 'name']\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f1690092a90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'clin_only'\n",
    "\n",
    "    # Otherwise the dataset type can be queried by a simple if chain\n",
    "    components = []\n",
    "    # Whether the dataset is slice-based or vertebreal-based metrics\n",
    "    if 'perslice' in data_label:\n",
    "        components.append('slice')\n",
    "    elif 'vertebral' in data_label:\n",
    "        components.append('vert')\n",
    "    else:\n",
    "        components.append('unkData')\n",
    "\n",
    "    # Whether the database includes clinical as well (full) or just image-derived\n",
    "    if 'full' in data_label:\n",
    "        components.append('full')\n",
    "    else:\n",
    "        components.append('img_only')\n",
    "\n",
    "    # Return the concatenated results\n",
    "    return '_'.join(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb783a-2e05-464e-99a8-037f79f3449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vert_range(data_label):\n",
    "    # Then whether its in the C2C6 or C2C7 range\n",
    "    if 'c2c6' in data_label:\n",
    "        return 'C2C6'\n",
    "    elif 'c2c7' in data_label:\n",
    "        return 'C2C7'\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aad00b956de637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_seg_algo(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'none'\n",
    "\n",
    "    # Get the segmentation algorithm\n",
    "    if 'binary' in data_label:\n",
    "        return 'binary'\n",
    "    elif 'soft' in data_label:\n",
    "        return 'soft'\n",
    "    return 'unkSeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf9f25fd0cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_contrast(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'none'\n",
    "\n",
    "    # Currently only T1 and T2 contrasts exist\n",
    "    if 'T1w' in data_label:\n",
    "        return 'T1'\n",
    "    elif 'T2w' in data_label:\n",
    "        return 'T2'\n",
    "    return 'unkContrast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959089bc96ea676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_orientation(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'none'\n",
    "\n",
    "    # Currently only T1 and T2 contrasts exist\n",
    "    if 'sag' in data_label:\n",
    "        return 'sag'\n",
    "    elif 'axial' in data_label:\n",
    "        return 'axial'\n",
    "    return 'unkOri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee48af69306561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pre_processing(data_label):\n",
    "    # We have 5 variants this time\n",
    "    if 'rfe_pca' in data_label:\n",
    "        return 'rfe_pca'\n",
    "    elif 'pca_rfe' in data_label:\n",
    "        return 'pca_rfe'\n",
    "    elif 'rfe' in data_label:\n",
    "        return 'rfe'\n",
    "    elif 'pca' in data_label:\n",
    "        return 'pca'\n",
    "    elif 'noprep' in data_label:\n",
    "        return 'none'\n",
    "    return 'unkPrep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b1713-9069-4e57-9c12-aee466db015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {}\n",
    "\n",
    "bad_vals = 0\n",
    "\n",
    "analysis_idx = ['seg_algo', 'dataset', 'vert_range', 'model', 'weight', 'ori', 'prep']\n",
    "\n",
    "con = connect(db_source)\n",
    "n_studies = 0\n",
    "for t in tables:\n",
    "    # Pull the dataframe from the database\n",
    "    try:\n",
    "        df = pd.read_sql(\n",
    "            f\"SELECT * FROM {t}\", \n",
    "            con=con\n",
    "        )\n",
    "        n_studies += 1\n",
    "    except:\n",
    "        print(f\"Failed to read table {t}, ignoring it\")\n",
    "        bad_vals += 1\n",
    "        continue\n",
    "\n",
    "    # If the table represents a study which wasn't run to completion, end early and report it\n",
    "    if df.shape[0] < 1000:\n",
    "        print(f\"Study {t} was not completed\")\n",
    "        bad_vals += 1\n",
    "        continue\n",
    "\n",
    "    # Split the DataFrame's label into its components\n",
    "    label_comps = t.split('__')\n",
    "\n",
    "    # The model is always the second element of study tag\n",
    "    model = label_comps[1]\n",
    "\n",
    "    # Dataset is always the last element of the study tag\n",
    "    data_description = label_comps[-1]\n",
    "\n",
    "    # Interpret the data label bit by bit to build up the dataframe\n",
    "    df['seg_algo'] = parse_seg_algo(data_description)\n",
    "    df['dataset'] = parse_dataset(data_description)\n",
    "    df['vert_range'] = parse_vert_range(data_description)\n",
    "    df['model'] = model\n",
    "    df['weight'] = parse_contrast(data_description)\n",
    "    df['ori'] = parse_orientation(data_description)\n",
    "    df['prep'] = parse_pre_processing(data_description)\n",
    "\n",
    "    df_map[model + '_' + data_description] = df\n",
    "\n",
    "con.close()\n",
    "\n",
    "print(f\"\\nTotal No. bad values: {bad_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58198a-b430-42b3-91f0-09d5bf24afab",
   "metadata": {},
   "source": [
    "## Performance Metric Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e4735-83b7-4310-b2c1-bd2f873148f0",
   "metadata": {},
   "source": [
    "All metrics in the below index list are tracked for all analyses, so are safe to query (and stack) from all analytical permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c75c94-4887-42b6-9c5b-605f68790511",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_performance_metric_idxs = [\n",
    "    \"objective\",\n",
    "    \"balanced_accuracy (validate)\",\n",
    "    \"roc_auc (validate)\",\n",
    "    \"log_loss (validate)\",\n",
    "    \"balanced_accuracy (test)\",\n",
    "    \"sk_precision_perclass (test)\",\n",
    "    \"sk_recall_perclass (test)\",\n",
    "    \"sk_f1_perclass (test)\",\n",
    "    \"roc_auc (test)\",\n",
    "    \"log_loss (test)\",\n",
    "    \"importance_by_permutation (test)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a76c4-d55c-46c7-b7d3-10a6bc7f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_idxs = [\n",
    "    \"replicate\",\n",
    "    \"trial\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4aec0-32b5-4c31-b5b7-c75875ac3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_performance_metrics():\n",
    "    sub_dfs = []\n",
    "    for df in df_map.values():\n",
    "        sub_df = df.loc[:, [*analysis_idx, *study_idxs, *shared_performance_metric_idxs]]\n",
    "        sub_dfs.append(sub_df)\n",
    "    return pd.concat(sub_dfs)\n",
    "\n",
    "performance_metric_df = stack_performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adf258-18d4-499f-a5ab-5166b8ed275a",
   "metadata": {},
   "source": [
    "### Per-Class Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c68d2a-749c-4cee-aa39-57891ac18204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_metrics = [\n",
    "    \"sk_precision_perclass (test)\",\n",
    "    \"sk_recall_perclass (test)\",\n",
    "    \"sk_f1_perclass (test)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3026f-0429-465d-a319-68505b099684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_class_metrics(df, metric_col):\n",
    "    # Conver the string the values are strored in back to dictionary maps\n",
    "    metric_subset = df.loc[:, metric_col]\n",
    "    metric_subset = metric_subset.apply(lambda x: x.strip('{').strip('}').split(', '))\n",
    "    metric_subset = metric_subset.apply(lambda x: {y.split(': ')[0]: float(y.split(': ')[1]) for y in x})\n",
    "\n",
    "    # Make a copy of the dict to avoid issues later\n",
    "    ret_df = df.copy()\n",
    "    \n",
    "    # Add the new columns for each class in these dictionaries\n",
    "    class_keys = set([y for x in metric_subset for y in x])\n",
    "    for k in class_keys:\n",
    "        new_col_name = f\"{metric_col} [{k}]\"\n",
    "        ret_df[new_col_name] = metric_subset.apply(lambda x: x[k]).values\n",
    "\n",
    "    # Remove the original column\n",
    "    ret_df.drop(metric_col, axis=1)\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29721504-3b01-4ec5-bdae-f21de7650260",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in class_metrics:\n",
    "    performance_metric_df = unpack_class_metrics(performance_metric_df, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b770692-0d1f-4408-8aa1-d9645b0b687f",
   "metadata": {},
   "source": [
    "#### Save Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d38a0-7503-48f0-839d-6d00e0790040",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metric_df.to_csv('full_performance_metrics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec27bd8-67fb-43dd-8a32-b87bf113a6ed",
   "metadata": {},
   "source": [
    "# Patient Metric Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61272b01-a632-4658-88b8-7fb962edef71",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbb261-4dc6-47da-9d03-e48debb2f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_metric_df = pd.read_csv(\"clinical_only.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f17c7e-c649-45d0-9900-3f446b28bca7",
   "metadata": {},
   "source": [
    "## mJOA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0329de6-5f8c-41ee-93bd-ae8f725977d9",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052f31f-72a7-4136-9aff-81894efc81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(data, cmap, legend_elements, xlabel, title, mean_offset=0, flip_mean_rot=False):\n",
    "    # Get the appropriate ranges for the data\n",
    "    min_range = int(np.min(data))-1\n",
    "    max_range = int(np.max(data))+1\n",
    "    \n",
    "    # Bin the data\n",
    "    hist, bins = np.histogram(\n",
    "        data, \n",
    "        np.array(range(min_range, max_range))+.1\n",
    "    )\n",
    "    \n",
    "    # Generate the figure\n",
    "    fig, ax = plt.subplots()\n",
    "        \n",
    "    # Iteratively color code the bars\n",
    "    for t, c in cmap.items():\n",
    "        mask = bins < t\n",
    "        to_display = np.array(range(min_range, t))+0.5\n",
    "        vals = hist[mask[:-1]]\n",
    "        ax.bar(\n",
    "            to_display, vals,\n",
    "            width=1, color=c,\n",
    "            align='edge',\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        \n",
    "    # Add a mean line\n",
    "    data_mean = np.mean(data)\n",
    "    ax.axvline(data_mean, ls='--', c='black')\n",
    "    if flip_mean_rot:\n",
    "        ax.text(data_mean-0.5, ax.get_ylim()[1]-mean_offset, f\"Mean ({data_mean:.4})\", rotation=90)\n",
    "    else:\n",
    "        ax.text(data_mean+0.05, ax.get_ylim()[1]-mean_offset, f\"Mean ({data_mean:.4})\", rotation=-90)\n",
    "        \n",
    "    # Add in the legend\n",
    "    ax.legend(handles=legend_elements)\n",
    "    \n",
    "    # Add in labels\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Return the figure and axis\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418cf0c-0560-4a09-8a4f-ae8d7a8402e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits so that all plots have consistent range\n",
    "xlim_min = int(np.min([*clinical_metric_df['mJOA initial'], *clinical_metric_df['mJOA 12 months']]))-1\n",
    "xlim_max = int(np.max([*clinical_metric_df['mJOA initial'], *clinical_metric_df['mJOA 12 months']]))+1\n",
    "\n",
    "ylim_min = 0\n",
    "ylim_max = int(np.max([\n",
    "    *np.histogram(clinical_metric_df['mJOA initial'], np.array(range(xlim_min, xlim_max))+.1)[0],\n",
    "    *np.histogram(clinical_metric_df['mJOA 12 months'], np.array(range(xlim_min, xlim_max))+.1)[0]\n",
    "]))+5\n",
    "\n",
    "# Color threshold map\n",
    "severity_cmap = {\n",
    "    18: 'blue',\n",
    "    17: 'green',\n",
    "    14: 'gold',\n",
    "    11: 'red'\n",
    "}\n",
    "\n",
    "# Generate a custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', edgecolor='black', label='Severe'),\n",
    "    Patch(facecolor='gold', edgecolor='black', label='Moderate'),\n",
    "    Patch(facecolor='green', edgecolor='black', label='Mild'),\n",
    "    Patch(facecolor='blue', edgecolor='black', label='Healthy'),\n",
    "]\n",
    "\n",
    "# DCM Severity labelling\n",
    "clinical_metric_df['DCM Severity initial'] = 'Severe'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA initial'] > 11, 'DCM Severity initial'] = 'Moderate'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA initial'] > 14, 'DCM Severity initial'] = 'Mild'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA initial'] > 17, 'DCM Severity initial'] = 'Healthy'\n",
    "\n",
    "clinical_metric_df['DCM Severity 12 months'] = 'Severe'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA 12 months'] > 11, 'DCM Severity 12 months'] = 'Moderate'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA 12 months'] > 14, 'DCM Severity 12 months'] = 'Mild'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA 12 months'] > 17, 'DCM Severity 12 months'] = 'Healthy'\n",
    "\n",
    "# Output path for the files\n",
    "mjoa_dist_out_path = Path('figures/mjoa_dist')\n",
    "if not mjoa_dist_out_path.exists():\n",
    "    mjoa_dist_out_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c24b1a-ffce-4a81-85e2-8f788547c1e1",
   "metadata": {},
   "source": [
    "### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab91fb5-9a81-4edf-bc08-997dfc2ac38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    # Plot the data\n",
    "    fig, ax = plot_distributions(\n",
    "        clinical_metric_df['mJOA initial'], severity_cmap, legend_elements,\n",
    "        'mJOA', 'Pre-Surgical mJOA Scores', 20\n",
    "    )\n",
    "    \n",
    "    # Plot the total number of each severity class as text\n",
    "    severity_counts = clinical_metric_df['DCM Severity initial'].value_counts()\n",
    "    ax.text(9, 15, f\"({severity_counts['Severe']})\", c='black', size=12, horizontalalignment='center')\n",
    "    ax.text(14, 44.5, f\"({severity_counts['Moderate']})\", c='black', size=12, horizontalalignment='center')\n",
    "    ax.text(16.5, 33, f\"({severity_counts['Mild']})\", c='black', size=12, horizontalalignment='center')\n",
    "    ax.text(18, 2.5, f\"({severity_counts['Healthy']})\", c='black', size=12, horizontalalignment='center')\n",
    "    \n",
    "    # Save and show the result\n",
    "    if not skip_plots:\n",
    "        fig.savefig(mjoa_dist_out_path / 'pre_treatment_mjoa.svg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d113761-8c0c-4e35-af5c-ee50440fbfc7",
   "metadata": {},
   "source": [
    "### 12 Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26d7cc-1fef-4474-a8e9-e4b24fb7785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    # Plot the data\n",
    "    fig, ax = plot_distributions(\n",
    "        clinical_metric_df['mJOA 12 months'], severity_cmap, legend_elements,\n",
    "        'mJOA', 'Post-Surgical mJOA Scores', 20, flip_mean_rot=True\n",
    "    )\n",
    "    \n",
    "    # Plot the total number of each severity class as text\n",
    "    severity_counts = clinical_metric_df['DCM Severity 12 months'].value_counts()\n",
    "    ax.text(8.5, 3, f\"({severity_counts['Severe']})\", c='black', size=12, horizontalalignment='center')\n",
    "    ax.text(13.5, 36, f\"({severity_counts['Moderate']})\", c='black', size=12, horizontalalignment='center')\n",
    "    ax.text(16, 45, f\"({severity_counts['Mild']})\", c='black', size=12, horizontalalignment='center')\n",
    "    ax.text(18, 37, f\"({severity_counts['Healthy']})\", c='black', size=12, horizontalalignment='center')\n",
    "    \n",
    "    # Save and show the result\n",
    "    fig.savefig(mjoa_dist_out_path / 'post_treatment_mjoa.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01ffb3-73de-4f92-9529-f488ff396cf8",
   "metadata": {},
   "source": [
    "### mJOA Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28350353-d34b-4dd5-a596-d1885dd2a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new color scheme and legend for this new style of data\n",
    "delta_cmap = {\n",
    "    8: 'springgreen',\n",
    "    0: 'white',\n",
    "    -1: 'salmon'\n",
    "}\n",
    "\n",
    "delta_legend_elements = [\n",
    "    Patch(facecolor='springgreen', edgecolor='black', label='Improved'),\n",
    "    Patch(facecolor='white', edgecolor='black', label='No Change'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Declined'),\n",
    "]\n",
    "\n",
    "xticks = (\n",
    "    list(range(-8, 9, 2)),\n",
    "    list(range(-8, 9, 2))\n",
    ")\n",
    "\n",
    "deltas = clinical_metric_df['mJOA 12 months'] - clinical_metric_df['mJOA initial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea28752-a836-48ab-83b1-3567c4c23e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the deltas\n",
    "if not skip_plots:\n",
    "    fig, ax = plot_distributions(\n",
    "        deltas, delta_cmap, delta_legend_elements, \n",
    "        \"mJOA Change\", 'Change in mJOA 1 Year Post-Surgery', 20, flip_mean_rot=True\n",
    "    )\n",
    "    \n",
    "    # Plot the total number of each severity class as text\n",
    "    change_counts = pd.cut(\n",
    "        deltas, \n",
    "        [-20, -1, 0, 20], \n",
    "        labels=['Declined', 'No Change', 'Improved']\n",
    "    ).value_counts()\n",
    "    ax.text(-4.5, 9, f\"({change_counts['Declined']})\", c='black', size=12, verticalalignment='center')\n",
    "    ax.text(-0.6, 40, f\"({change_counts['No Change']})\", c='black', size=12, verticalalignment='center')\n",
    "    ax.text(4, 32, f\"({change_counts['Improved']})\", c='black', size=12, verticalalignment='center')\n",
    "    \n",
    "    # Save and show the result\n",
    "    fig.savefig(mjoa_dist_out_path / 'treatment_mjoa_delta.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b446d5-eb86-43f6-a875-1b68faf8e95b",
   "metadata": {},
   "source": [
    "## Hirayabashi Recovery Ratio Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5d7f7-e9b0-4b60-90bf-22c28b223f1e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fa902-ec49-44d3-80ab-5fd21a731fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Plot the KDE distribution onto an existing plot\n",
    "def plot_kde(ax, values, c='black', ls='-', label=None):\n",
    "    kde = gaussian_kde(values)\n",
    "    kde.covariance_factor = lambda: 0.15\n",
    "    kde._compute_covariance()\n",
    "    xs = np.linspace(np.min(values), np.max(values), 200)\n",
    "    ys = kde(xs)\n",
    "    ys /= np.linalg.norm(ys)\n",
    "    if label == None:\n",
    "        ax.plot(xs, ys, ls=ls, c=c)\n",
    "    else:\n",
    "        ax.plot(xs, ys, ls=ls, c=c, label=label)\n",
    "\n",
    "# Clean out invalid values from the set\n",
    "def clean_vals(df):\n",
    "    df2 = df[df != -np.inf]\n",
    "    df2 = df2.dropna()\n",
    "    return df2\n",
    "\n",
    "# Adds important reference lines to the plot\n",
    "def draw_line_references(ax):\n",
    "    # Significant improvement\n",
    "    ax.axvline(0.5, ls='-.', c='grey')\n",
    "    \n",
    "    # Baselines\n",
    "    ax.axhline(0, ls=\":\",  c='lightgrey') \n",
    "    ax.axvline(0, ls=\":\",  c='lightgrey')\n",
    "\n",
    "# The HRR Equation, for immediate reference within the plot\n",
    "hirabayashi_equation = r\"HRR = $\\frac{\\mathrm{mJOA (1 Year)} - \\mathrm{mJOA (Initial)}}{18 - \\mathrm{mJOA (Initial)}}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb740816-3b59-45d3-9165-23b4d5044e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    # Get the HRR for our patients, skipping over initially healthy patients who could not improve whatsoever\n",
    "    hrr_df = clinical_metric_df.loc[clinical_metric_df['DCM Severity initial'] != \"Healthy\", 'HRR']\n",
    "    \n",
    "    # Generate the initial plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plot our reference lines\n",
    "    draw_line_references(ax)\n",
    "    \n",
    "    # Plot the distributions by their initial severity class\n",
    "    plot_kde(\n",
    "        ax, clean_vals(hrr_df[clinical_metric_df['DCM Severity initial'] == 'Severe']), ls='--', c='red', label='Severe'\n",
    "    )\n",
    "    plot_kde(\n",
    "        ax, clean_vals(hrr_df[clinical_metric_df['DCM Severity initial'] == 'Moderate']), ls='--', c='gold', label='Moderate'\n",
    "    )\n",
    "    plot_kde(\n",
    "        ax, clean_vals(hrr_df[clinical_metric_df['DCM Severity initial'] == 'Mild']), ls='--', c='green', label='Mild'\n",
    "    )\n",
    "    \n",
    "    # Plot the overall distribution\n",
    "    plot_kde(ax, hrr_df, c='blue', label='All')\n",
    "    \n",
    "    # Calculate the ratio above and below the HRR significance threshold, and add it\n",
    "    good_ratio = np.sum(hrr_df >= 0.5)/hrr_df.shape[0]\n",
    "    fair_ratio = np.sum(hrr_df < 0.5)/hrr_df.shape[0]\n",
    "    \n",
    "    ax.text(0.7, 0.238, f\"{good_ratio: .2f}\", c='purple')\n",
    "    ax.text(-0.5, 0.238, f\"{fair_ratio: .2f}\", c='purple')\n",
    "    \n",
    "    # Add axis labels\n",
    "    ax.set_xlabel('Hirabayashi Recovery Ratio (HRR)')\n",
    "    ax.set_ylabel('Normalized Kernel Density Estimate')\n",
    "    \n",
    "    # Add a legend\n",
    "    ax.legend(title='Pre-Surgical DCM Severity')\n",
    "    \n",
    "    # Add hirabayashi equation directly to plot\n",
    "    ax.text(-8, 0.15, hirabayashi_equation)\n",
    "    \n",
    "    # Add a title\n",
    "    ax.set_title(\"Distribution of Hirabayashi Recovery Ratio\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(mjoa_dist_out_path / 'hirabayashi_ratios.svg')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd6a81-39c2-4261-80e7-27aeb53bfe14",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0180f-32c6-4d15-a3b9-b3a32ecc07d0",
   "metadata": {},
   "source": [
    "### Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b9b24-3298-41a2-95aa-b34716f64fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_continuous_demographics(col, **kwargs):\n",
    "    sns.displot(clinical_metric_df, x=col, **kwargs)\n",
    "    plt.title(f\"Patient Distribution ({col})\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/demo_dist/{'_'.join(col.lower().split(' '))}_dist.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7cf74-7a3d-42e7-915e-dcd2d1f7f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"figures/demo_dist/\")\n",
    "if not out_path.exists():\n",
    "    out_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9a004-0fed-4578-bc59-0b841e556455",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8dca23-6ad4-4ec5-a4b5-528ef117b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    plot_continuous_demographics(\"Age\", bins=range(20, 90, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1bf08-da5c-41d1-90b0-ba65eadc757f",
   "metadata": {},
   "source": [
    "#### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a357f53-8841-47cc-98d2-316f754b4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    plot_continuous_demographics(\"BMI\", bins=range(15, 51, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e6ff2-ef4f-4cd8-8a8d-c28f0b342b2d",
   "metadata": {},
   "source": [
    "### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62aa0f7-224b-4472-b0c1-817ac77cce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_demographics(col):\n",
    "    col_counts = clinical_metric_df[col].value_counts()\n",
    "    plt.pie(col_counts, labels=None, autopct=lambda x: f'{x: .2f}%')\n",
    "    plt.legend(labels=col_counts.index)\n",
    "    plt.title(f\"Patient Distribution ({col})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/demo_dist/{'_'.join(col.lower().split(' '))}_dist.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61d26d-45f4-469d-9833-5905b5a3bcbb",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f5a7e-fa2d-4c39-a960-f502acd5e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    plot_categorical_demographics(\"Sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f0b01-4703-468b-a44d-60487360cdc7",
   "metadata": {},
   "source": [
    "#### Work Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1657a8-91bf-47da-bda6-acee47aef31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    plot_categorical_demographics(\"Work Status (Category)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be021d2-7945-45d8-b7eb-13b667ad76ef",
   "metadata": {},
   "source": [
    "#### Symptom Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd1c41-f514-4002-9d85-e98942cfc8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    plot_categorical_demographics(\"Symptom Duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871d17a-daa4-4cec-bd9a-f89f0cc8a997",
   "metadata": {},
   "source": [
    "# Best across Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfdffd3-3046-46dc-bec6-197ed66bd4a3",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bb027-815a-4a52-917f-73a0e33aa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_across_trials_idx = [*analysis_idx, 'Mean', 'STD']\n",
    "best_across_trials_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15301ad6-9a43-4ab8-8a46-761212991ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the values of one column when the value of another is among the n-highest (default to n=1)\n",
    "def get_peak_at_max_other(target_col, other_col, df=performance_metric_df, n=1, ascending=[True]) -> pd.DataFrame:\n",
    "    # Get the best value per analytical grouping and replicate across all trials\n",
    "    peak_value_df = df.sort_values(by=other_col, ascending=ascending).groupby([*analysis_idx, 'replicate']).tail(n)\n",
    "\n",
    "    # Set up the return dataframe\n",
    "    analysis_groups = peak_value_df.reset_index().groupby(analysis_idx)\n",
    "    value_means = analysis_groups[target_col].mean()\n",
    "    value_stds = analysis_groups[target_col].std()\n",
    "    return_df = pd.DataFrame(index=list(value_means.index))\n",
    "    return_df['Mean'] = value_means\n",
    "    return_df['STD'] = value_stds\n",
    "\n",
    "    # Return the result\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53b50b-049b-489c-805f-d70bb0d1bb96",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6069b01-234f-41db-b816-d83abccf309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force the target column to act as a float, as occasionally \"null\" values slip through and make it act like strings\n",
    "performance_metric_df.loc[:, ['balanced_accuracy (test)', 'balanced_accuracy (validate)']] = \\\n",
    "    performance_metric_df.loc[:, ['balanced_accuracy (test)', 'balanced_accuracy (validate)']].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d2a1c-0b11-4b33-b9c6-67dfc5264195",
   "metadata": {},
   "source": [
    "## Balanced Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea0023-0e48-4dda-92c8-2cbc1b06db6e",
   "metadata": {},
   "source": [
    "### Test @ Peak Validation **[MAIN RESULT]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee7174-4a17-479d-826a-5e30a91a1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_index = ['balanced_accuracy (validate)', 'objective']\n",
    "other_ascend = ascending=[True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfec9b2-e7d4-44f8-9096-5ed7d15236b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_testing_at_validation_df = get_peak_at_max_other('balanced_accuracy (test)', other_index, ascending=other_ascend).sort_values(by='Mean').tail(10)\n",
    "peak_testing_at_validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9494b-c626-41bf-8a18-29caa9a717a2",
   "metadata": {},
   "source": [
    "### Test @ Peak Test [Theoretical Potential]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3d85f-58a6-4358-b69e-2bb924f88d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_index = ['balanced_accuracy (test)', 'objective']\n",
    "other_ascend = ascending=[True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88fa4e-7163-433d-b01b-71e779b38e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('balanced_accuracy (test)', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60b891-5a69-4fb0-94f8-c026c0c7ffbb",
   "metadata": {},
   "source": [
    "### Other Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d337e1-6d81-4243-bf17-ecb4b664baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_index = ['balanced_accuracy (validate)', 'objective']\n",
    "other_ascend = ascending=[True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2331e31-5399-46d4-8904-58cb5ff2434d",
   "metadata": {},
   "source": [
    "#### Precision (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89053c4-a77f-48c7-8d00-d969940749fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('sk_precision_perclass (test) [good]', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bddfe-2818-4c7f-9b76-927688da501d",
   "metadata": {},
   "source": [
    "#### Recall (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bf424-8b90-4f3c-8366-04d4563d8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('sk_recall_perclass (test) [good]', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a974975-8151-4938-b912-4f8f587f1f9b",
   "metadata": {},
   "source": [
    "#### F1-Score (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b018647-79ba-40ae-a2c3-c7df0e419ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('sk_f1_perclass (test) [good]', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a42ab-0498-43d5-807f-1aa14c226e68",
   "metadata": {},
   "source": [
    "#### Precision (Fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42c34d-5470-422b-921a-a7d67526a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('sk_precision_perclass (test) [fair]', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a52a1-3d12-42c7-9aae-b08c356cbed0",
   "metadata": {},
   "source": [
    "#### Recall (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809093e-2648-485c-b4b1-492caecf4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('sk_recall_perclass (test) [fair]', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fdd8f9-4a99-43a2-b136-796f1c45ddbe",
   "metadata": {},
   "source": [
    "#### F1-Score (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9c8ad-0ff5-48e6-b91f-dd4676f496e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('sk_f1_perclass (test) [fair]', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae5e56-6302-4961-b949-79eb900ea8e2",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72417adc-a2e2-4cec-a211-f0e213807480",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metric_df['roc_auc (test)'] = performance_metric_df['roc_auc (test)'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c2a7e-b452-40a3-8d43-9e4a58103afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('roc_auc (test)', other_index, ascending=ascending).sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3d404-e520-4ee5-9734-2ee0e00ad774",
   "metadata": {},
   "source": [
    "# Performance Across Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9383a84-3b77-4352-9e45-6b47fbd3151b",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff682b-347b-4004-8adb-8470e7b8b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_performance_across_trials(df, metric, grouping, fpath):\n",
    "    # Plot the average and standard deviation\n",
    "    sns.lineplot(data=df, x='trial', y=metric, hue=grouping)\n",
    "\n",
    "    # Add details\n",
    "    plt.title(f'By {grouping.capitalize()} (Average)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.savefig(fpath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b116a5-ab3e-4387-b1f3-626b8e91b0c7",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248169f-4ee4-4115-b23c-e27441b58943",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    output_dir = Path(\"figures/bacc_performance/\")\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir(parents=True)\n",
    "    \n",
    "    for i in analysis_idx:\n",
    "        plot_average_performance_across_trials(performance_metric_df, 'balanced_accuracy (test)', i, output_dir/f'bacc_avg_by_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474a6ad-9f6e-40ef-88be-ea416c9ca155",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test) at Peak Balanced Accuracy (Validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43725ba8-1975-4b89-b429-c1e77ce6aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_at_peak_other_across_trials(df, metric, other, grouping, fpath):\n",
    "    # Reformat the data to be max by trial/replicate grouping\n",
    "    tmp_df = df.sort_values(other).groupby(['replicate', 'trial', grouping]).tail(1).reset_index()\n",
    "    \n",
    "    # Plot the average and standard deviation\n",
    "    sns.lineplot(data=tmp_df, x='trial', y=metric, hue=grouping)\n",
    "\n",
    "    # Add details\n",
    "    plt.title(f'By {grouping.capitalize()} (B.Acc Test @ Peak Validation)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.savefig(fpath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d9d92-9343-446f-bcbe-f39f1359a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    for i in analysis_idx:\n",
    "        plot_metric_at_peak_other_across_trials(performance_metric_df, 'balanced_accuracy (test)', 'balanced_accuracy (validate)', i, output_dir/f'bacc_test_at_peak_validate_by_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa491634-113a-4ce2-912a-758981068e16",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test) Weighted by Balanced Accuracy (Validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2434b-76d4-46ff-a567-ea996f6ce7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_std(vals, weights):\n",
    "    mean_val = np.average(vals, weights=weights)\n",
    "    n = vals.shape[0]\n",
    "    var_val= np.average((vals-mean_val)**2, weights=weights) * (n/(n-1))\n",
    "    std_val = np.sqrt(var_val)\n",
    "    return std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f118e-6bc9-4b31-9809-54e1abf1735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_weighted_by_other(df, metric, weight, grouping, fpath):\n",
    "    # Calculate the weighted metrics from the original dataset\n",
    "    df_groupedby = df.loc[:, [grouping, *study_idxs, metric, weight]].groupby([grouping, 'trial'])\n",
    "    mean_vals = df_groupedby.apply(lambda x: np.average(x[metric], weights=x[weight]), include_groups=False)\n",
    "    std_vals = df_groupedby.apply(lambda x: weighted_std(x[metric], x[weight]), include_groups=False)\n",
    "    \n",
    "    sub_df = pd.DataFrame()\n",
    "    sub_df['Mean'] = mean_vals\n",
    "    sub_df['STD'] = std_vals\n",
    "\n",
    "    # Plot each of them iteratively, w/ weighted mean and std\n",
    "    fig, ax = plt.subplots(1)\n",
    "    group_options = set(df[grouping])\n",
    "    for i, g in enumerate(group_options):\n",
    "        # Plot the main line\n",
    "        y = sub_df.reset_index().query(f\"{grouping} == '{g}'\")\n",
    "        y_mean = y.groupby('trial')['Mean'].mean()\n",
    "        ax.plot(y_mean, label=g)\n",
    "\n",
    "        # Plot the (weighted) standard deviation fills\n",
    "        y_std = y.groupby('trial')['STD'].mean()\n",
    "        ax.fill_between(np.arange(y_std.shape[0]), y_mean+y_std, y_mean-y_std, facecolor=f'C{i}', alpha=0.2)\n",
    "\n",
    "    # Add other plotted elements\n",
    "    plt.xlabel('Trial')\n",
    "    plt.ylabel('Weighted Average')\n",
    "    plt.legend(title=grouping)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e0313-55f1-4810-9ad9-bdbce9a6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    for i in analysis_idx:\n",
    "        metric_weighted_by_other(performance_metric_df, 'balanced_accuracy (test)', 'balanced_accuracy (validate)', i, output_dir/f'bacc_weighted_avg_by_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e99e8b-13ee-4ca6-8486-ac69f7d9ba8c",
   "metadata": {},
   "source": [
    "# Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb963b73-3a75-4c9c-a6ca-246f42f857cf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb0928-c546-4b1f-bc10-47c76357ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "from scipy.stats import ranksums, kruskal, false_discovery_control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74469ad1-a268-4bb7-9781-9662e5752be9",
   "metadata": {},
   "source": [
    "Target metric gathering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e29e5-bfaa-406d-9228-4f01903673e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute peak values by replicate, mean and std\n",
    "def get_best_per_replicate(target_value):\n",
    "    component_dfs = []\n",
    "    for k, df in df_map.items():\n",
    "        peak_df = df.sort_values(by=target_value).groupby('replicate').last()\n",
    "        peak_df = peak_df.loc[:, [*analysis_idx, 'trial', target_value]]\n",
    "        component_dfs.append(peak_df)\n",
    "    result_df = pd.concat(component_dfs).reset_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29494e-3290-4d5b-b382-cd2e1f2f495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of one metric, sampled at the peak value of another, per-replicate mean and STD sampled\n",
    "def get_val_at_best_other_per_replicate(target, other, fallback=None, ascending=True, fallback_ascending=True):\n",
    "    component_dfs = []\n",
    "\n",
    "    \n",
    "    if fallback is not None:\n",
    "        other_idx = [other, fallback]\n",
    "        ascending_ls = [ascending, fallback_ascending]\n",
    "    else:\n",
    "        other_idx = other\n",
    "        ascending_ls = ascending\n",
    "    \n",
    "    for k, df in df_map.items():\n",
    "        # Get the 'best' value in the set, as sorted by other\n",
    "        peak_other = df.sort_values(by=other_idx, ascending=ascending_ls).groupby('replicate').last()[other]\n",
    "\n",
    "        # For each entry in the peak values, query the sub_df which matches \n",
    "        comp_dfs = []\n",
    "        for rep_idx in peak_other.index:\n",
    "            peak_val = peak_other[rep_idx]\n",
    "            sub_df = df.query(f\"replicate == {rep_idx}\")\n",
    "            sub_df = sub_df.loc[sub_df[other] == peak_val, :]\n",
    "            comp_dfs.append(sub_df)\n",
    "            \n",
    "        # Extend the DF with the new value(s)\n",
    "        peak_df = pd.concat(comp_dfs).loc[:, [*analysis_idx, 'replicate', target, other]]\n",
    "\n",
    "        # Append the result to our list\n",
    "        component_dfs.append(peak_df)\n",
    "    result_df = pd.concat(component_dfs).reset_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c576c18-a23f-4aac-a534-1fccac6d7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_keys = {\n",
    "    'two-sided': '!=',\n",
    "    'greater':   '>',\n",
    "    'less':      '<'\n",
    "}\n",
    "\n",
    "def paired_rankedsum(df, query, target, alternative='two-sided'):\n",
    "    pvals = {}\n",
    "    query_set = set(df[query])\n",
    "\n",
    "    # Caclulate the native rankedsum p-value for each pair of datasets, testing whether the former's value is greater than the latters\n",
    "    for v1, v2 in permutations(query_set, 2):\n",
    "        x1 = df.query(f\"{query} == '{v1}'\")[target]\n",
    "        x2 = df.query(f\"{query} == '{v2}'\")[target]\n",
    "        p = ranksums(x1, x2, alternative=alternative).pvalue\n",
    "        pvals[f\"{v1} {alt_keys[alternative]} {v2}\"] = [p]\n",
    "\n",
    "    # Save the results as a dataframe\n",
    "    return_df = pd.DataFrame.from_dict(pvals).T\n",
    "    return_df.index.name = 'Comparison'\n",
    "    return_df.columns = ['p']\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4112b1d-99d1-4a9d-b939-0d4bfab9a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kw(df, grouping, target):\n",
    "    query_set = set(df[grouping])\n",
    "    samples = [df.query(f\"{grouping} == '{q}'\")[target] for q in query_set]\n",
    "    return kruskal(*samples).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a754f-899f-45c9-a9ea-d1a1e21b2fc0",
   "metadata": {},
   "source": [
    "## Testing Balanced Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5fb66-24ab-44d4-8ed3-a1faa838c327",
   "metadata": {},
   "source": [
    "### Testing @ Peak Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f258de9-0c58-423b-813d-cb4a4f4d5c1b",
   "metadata": {},
   "source": [
    "#### Raw Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dda71-9fa8-47fe-a7e9-9cbac4ed718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'balanced_accuracy (test)'\n",
    "other = 'balanced_accuracy (validate)'\n",
    "fallback = 'objective'\n",
    "replicate_test_at_peak_bacc_df = get_val_at_best_other_per_replicate(target, other, fallback, fallback_ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d25719-926c-4fe5-8818-2fd245ba3107",
   "metadata": {},
   "source": [
    "#### Ranked-Sum Grouping Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366d7ae-5bf1-4a4c-aa44-af4a2644f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for whether one experimental permutation has greater average balanced accuracy performance than another\n",
    "sub_dfs = []\n",
    "for k in analysis_idx:\n",
    "    tmp_df = paired_rankedsum(replicate_test_at_peak_bacc_df, k, target, alternative='greater')\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "sig_test_at_peak_valid_df = pd.concat(sub_dfs).sort_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417a3f6-4e66-47c7-bb78-7a27c1372dee",
   "metadata": {},
   "source": [
    "Bonferonni False Detection Correction **[Extremely Conservative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f4659-100b-4e3a-a199-d7d70e7dff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_valid_df['significance (bonferonni)'] = ''\n",
    "bf_ps = sig_test_at_peak_valid_df['p'] * sig_test_at_peak_valid_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_valid_df.loc[bf_ps < t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97889f-5507-4a43-a3e1-ea57791321ff",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli False-Detection Correction **[Less Conservative, chosen over Benjamini-Hochberg due to our tests not being completely independent]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fff7d4-1ab4-4251-b7e3-df89151a944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_valid_df['significance (benjaminini-yekutieli)'] = ''\n",
    "by_ps = false_discovery_control(sig_test_at_peak_valid_df['p'], method='by')\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_valid_df.loc[by_ps < t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d91a5-f530-4524-905f-42ae962c621e",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274743cf-0cb2-49d8-9083-d2f05bb1cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_at_peak_valid_df.reset_index().head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e38bf-d76e-4598-a08c-04ad91479360",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379303ef-6892-47ba-b845-af452ddf7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kruskal-Wallace, confirm that there is a significant difference in the best-case performance for each analytical variation\n",
    "kw_pvals = {}\n",
    "for i in analysis_idx:\n",
    "    kw_pvals[i] = [evaluate_kw(replicate_test_at_peak_bacc_df, i, 'balanced_accuracy (test)')]\n",
    "kw_df = pd.DataFrame.from_dict(kw_pvals).T\n",
    "kw_df.columns = ['p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ab5b6a-b69b-415d-b4cc-a5d135ca06c5",
   "metadata": {},
   "source": [
    "Bonferonni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd79bcd-0ea5-491a-893d-6f78b341f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (bonferonni)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ab938-c30f-4d12-886d-0df792915670",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3453ff7-1c26-426f-a193-9801230462cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (benjaminini-yekutieli)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cee48a-e649-4e12-a94a-07852bc48090",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fd9d7-585c-4ee3-b6f4-77a2a820313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6a892-581b-4adc-b177-ebe6270483aa",
   "metadata": {},
   "source": [
    "### Testing @ Peak Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575d0b7-3ff1-44ae-95a9-b086bfdc3429",
   "metadata": {},
   "source": [
    "#### Raw Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8a7bc-c3d6-4b37-98fb-355113126f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'balanced_accuracy (test)'\n",
    "other = 'objective'\n",
    "replicate_test_at_peak_obj_df = get_val_at_best_other_per_replicate(target, other, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bbd80-cf2c-466f-98aa-81fce6adac02",
   "metadata": {},
   "source": [
    "#### Ranked-Sum Grouping Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc9748-ad49-406d-a391-2aec8b807eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for whether one experimental permutation has greater average balanced accuracy performance than another\n",
    "sub_dfs = []\n",
    "for k in analysis_idx:\n",
    "    tmp_df = paired_rankedsum(replicate_test_at_peak_obj_df, k, target, alternative='greater')\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "sig_test_at_peak_obj_df = pd.concat(sub_dfs).sort_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebead67-b547-4a32-a165-59bca9c24f5d",
   "metadata": {},
   "source": [
    "Bonferonni False Detection Correction **[Extremely Conservative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dbb77-83d7-4c1e-ba3a-f43aae51dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_obj_df['significance (bonferonni)'] = ''\n",
    "bf_ps = sig_test_at_peak_obj_df['p'] * sig_test_at_peak_obj_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_obj_df.loc[bf_ps < t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a334b6-dc43-4edd-8679-2faea62a1f83",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli False-Detection Correction **[Less Conservative, chosen over Benjamini-Hochberg due to our tests not being completely independent]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65fef7d-af2c-4289-b62a-b789eb38669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_obj_df['significance (benjaminini-yekutieli)'] = ''\n",
    "by_ps = false_discovery_control(sig_test_at_peak_obj_df['p'], method='by')\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_obj_df.loc[by_ps < t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d2238-97ea-409f-b74b-f5877577cfb1",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dfceae-e930-4f41-a2b6-9ec81145a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_at_peak_obj_df.reset_index().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d775c15-a66a-4894-a06d-aa6670cae15f",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18af0-d1bd-4cd3-8c61-450e7f4daed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kruskal-Wallace, confirm that there is a significant difference in the best-case performance for each analytical variation\n",
    "kw_pvals = {}\n",
    "for i in analysis_idx:\n",
    "    kw_pvals[i] = [evaluate_kw(replicate_test_at_peak_obj_df, i, 'balanced_accuracy (test)')]\n",
    "kw_df = pd.DataFrame.from_dict(kw_pvals).T\n",
    "kw_df.columns = ['p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b941440-037b-43e4-921c-b1c20a47cb6e",
   "metadata": {},
   "source": [
    "#### Bonferonni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7bd5f-cfaf-4cc1-891e-e44c109c2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (bonferonni)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f3b58-c370-433b-9730-c8002f6fb318",
   "metadata": {},
   "source": [
    "#### Benjaminini-Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4566672-d42f-4316-9a04-87c3787a8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (benjaminini-yekutieli)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee5af3-a86f-4ec5-ad8d-2796e448f1c0",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e1f767-681e-44f8-89a4-27cc087163f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f8e27-6b04-40cd-8153-3d12f85307c5",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc2509-ff5c-4ec7-97e7-c9632dd3b45c",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74bd963-7fc0-49ae-b481-c667a37a7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_feature_imp(val):\n",
    "    # Strip leading and trailing brackets\n",
    "    val = val[1:-2]\n",
    "\n",
    "    # Create a dictionary from the remaining components\n",
    "    imp_dict = dict()\n",
    "    for v in val.split(', '):\n",
    "        vcomps = v.split(': ')\n",
    "        k = ': '.join(vcomps[:-1])\n",
    "        v = float(vcomps[-1])\n",
    "        imp_dict[k] = v\n",
    "        \n",
    "    return imp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5bee5-930a-448e-99be-dfcee856a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp_report(df: pd.DataFrame, feature_col, weight_col) -> pd.DataFrame:\n",
    "    # Convert the dictionaries contained with the feature_col dicts into dataframes which can be stacked\n",
    "    raw_dfs = []\n",
    "    weighted_dfs = []\n",
    "    for r in df.iterrows():\n",
    "        rvals = r[1]\n",
    "        tmp_df = pd.DataFrame.from_dict({k: [v] for k, v in rvals[feature_col].items()})\n",
    "        raw_dfs.append(tmp_df)\n",
    "\n",
    "    # Stack the dataframes\n",
    "    raw_feature_imps = pd.concat(raw_dfs).fillna(0)\n",
    "\n",
    "    # Query the weights list a single time to avoid repeated querying expense\n",
    "    weights = df[weight_col].astype('float64')\n",
    "    \n",
    "    # For each feature, calculate our desired statistics\n",
    "    return_cols = ['Mean', 'STD', 'Weighted Mean', 'Weighted STD']\n",
    "    return_df_dict = {}\n",
    "    for c in raw_feature_imps.columns:\n",
    "        # Single query of the dataframe, as pandas can be slow w/ repeated queries\n",
    "        samples = raw_feature_imps[c]\n",
    "        # Raw Mean\n",
    "        c_mean = np.mean(samples)\n",
    "        # Raw STD\n",
    "        c_std = np.std(samples)\n",
    "        # Weighted mean\n",
    "        c_mean_weighted = np.average(samples, weights=weights)\n",
    "        # Weighted STD\n",
    "        c_std_weighted = weighted_std(samples, weights)\n",
    "        # Stack them into a list and store it in the dictionary\n",
    "        return_df_dict[c] = [c_mean, c_std, c_mean_weighted, c_std_weighted]\n",
    "\n",
    "    # Return the result as a dataframe\n",
    "    return pd.DataFrame.from_dict(return_df_dict, columns=return_cols, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6a5a1-b404-458d-8c48-96f958cea7c3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1798fd-75d9-4364-8c9a-c549a655b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate and stack the information relative to the value\n",
    "sub_dfs = []\n",
    "\n",
    "for df in df_map.values():\n",
    "    tmp_df = df.loc[:, [*study_idxs, *analysis_idx, 'balanced_accuracy (test)', 'importance_by_permutation (test)']]\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "feature_imp_df = pd.concat(sub_dfs)\n",
    "\n",
    "# Isolate only the best trial from each replicate\n",
    "feature_imp_df = feature_imp_df.sort_values('balanced_accuracy (test)').groupby([*analysis_idx, 'replicate']).tail(1).set_index(analysis_idx)\n",
    "\n",
    "# Parse the feature importance list into a cleaner dictionary\n",
    "feature_imp_df['importance_by_permutation (test)'] = feature_imp_df['importance_by_permutation (test)'].apply(format_feature_imp)\n",
    "feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1eaf4-20b7-4dc0-971f-eb8878f757a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate PCA-derived features from the rest\n",
    "pca_feature_imp_df = feature_imp_df.reset_index().loc[feature_imp_df.reset_index()['prep'].apply(lambda x: 'pca' in x), :].set_index([*analysis_idx])\n",
    "pca_feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2472b-9c5a-4984-ba62-c7b04eab4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpca_feature_imp_df = feature_imp_df.drop(pca_feature_imp_df.index)\n",
    "nonpca_feature_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a8fbf-9283-45a1-9e22-fb7b33875ea6",
   "metadata": {},
   "source": [
    "## Un-transformed Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a89023-df3e-480b-9358-d39635bafcf0",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6, Vertebral + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a715b7-8623-485f-9f75-b7cdf22cc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Weighted Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e51f0-642e-4da3-8def-88dd33110466",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C6, Vertebral Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954bda7-4083-4d28-97c3-9381d279ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad4172d-6f61-403a-b160-9aabe9c658ee",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6, Slice-Based + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab30078-d235-4bb6-8f6e-ef6449c0ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86979f3-ab35-4bc2-8939-e6330e490377",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C6, Slice-Based Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45384b-6420-47a7-bf52-6bde4f8ebda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666ff53-f073-4028-bdc7-017dc6afe3a7",
   "metadata": {},
   "source": [
    "### Full dataset (C2C7, Vertebral + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329f464-8d11-424a-9934-d4a68cb4770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d091d-74e6-4f3a-aece-df6169d7426b",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C7, Vertebral Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82faba7f-218e-45e2-991d-6f3a69ea5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db8388-29eb-4102-829a-397f536534c8",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C7, Slice-Based+Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1f345-b7cd-4713-8f23-f38d302b0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1ad71-ac22-4684-b366-cb6fc6cd7510",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C7, Slice-Based Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb754c9-cc1f-46a8-8b72-37443d022c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32df16-f4b2-4db1-958f-c10a4184fb95",
   "metadata": {},
   "source": [
    "### Clinical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c18647-7cb0-40c0-82a8-a277a72110a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"dataset == 'clin_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0750b9-8536-4b82-83ee-b5c1807e97cb",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dab40-066a-4e3d-9d63-8d23ec690e50",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6, Vertebral + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4c3c2-4897-430b-8157-2e023aee9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8e864-aadc-4f89-aba2-370a0283064c",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6, Vertebral Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4ec3b-2e22-4411-bcce-76a61fe5f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc621b96-91d9-4858-a0df-454e6d2ba31e",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6, Slice-Based + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f401f20-238d-4bd7-a6f1-ef6da5a7fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc666d2c-afba-44ec-a5d6-452d05972fce",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6, Slice-Based Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73799a8-d811-4798-ac19-0348f5f8c48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591dfef-17c4-4564-9512-bdb2bdcf042d",
   "metadata": {},
   "source": [
    "### Full dataset (C2C7, Vertebral + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd5514-6709-422f-9887-2b20515ad361",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f6458-881a-4544-a8a8-3120bd10b50d",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C7, Vertebral Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc66efd-a2ea-448d-8d31-1248e724445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b70786-1226-470f-a5b8-84e440d56502",
   "metadata": {},
   "source": [
    "### Full dataset (C2C7, Slice-Based + Clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52eb850-ee8c-42b1-8deb-ac93620ce940",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_full'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27426c-c3d8-4cf9-8c4b-a477387d0a2e",
   "metadata": {},
   "source": [
    "### Full dataset (C2C7, Slice-Based Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850871a0-820d-4034-a53a-a3bc20a1045c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"vert_range == 'C2C7'\")\n",
    "query_df = query_df.query(\"dataset == 'slice_img_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd6a43-ddd1-4b33-8d29-193db73d98c6",
   "metadata": {},
   "source": [
    "### Clinical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae64961-ddc6-4183-8032-9d34429fff40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df = pca_feature_imp_df.query(\"dataset == 'clin_only'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afddc95-a162-4c4a-91a5-9087ee5176ff",
   "metadata": {},
   "source": [
    "#### Feature Importance of Best Performing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d44657-b919-4ed0-bc15-0804e1213c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.query(\"vert_range == 'C2C6'\")\n",
    "query_df = query_df.query(\"dataset == 'vert_full'\")\n",
    "query_df = query_df.query(\"model == 'RandomForestClassifier'\")\n",
    "query_df = query_df.query(\"seg_algo == 'binary'\")\n",
    "query_df = query_df.query(\"weight == 'T1'\")\n",
    "query_df = query_df.query(\"ori == 'sag'\")\n",
    "query_df = query_df.query(\"prep == 'rfe'\")\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c49f5-6b87-4074-977e-a2ac4e7d2be0",
   "metadata": {},
   "source": [
    "#### Feature Importance of 10 Best Performing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3296815-dac5-454d-a682-ef575e7a3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = nonpca_feature_imp_df.sort_values(['balanced_accuracy (test)']).tail(10)\n",
    "query_report = feature_imp_report(query_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "query_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac539e-203a-4553-aca7-e347b832727d",
   "metadata": {},
   "source": [
    "## Best Model Performance-over-Time Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fe78c-563f-4e97-b4a0-f4f631582415",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vals = {}\n",
    "for k, v in df_map.items():\n",
    "    best_model = v.sort_values(['balanced_accuracy (validate)', 'objective'], ascending=[True, False]).groupby('replicate').tail(1)\n",
    "    model_mean = best_model['balanced_accuracy (test)'].astype('float64').mean()\n",
    "    model_vals[k] = model_mean\n",
    "\n",
    "best_models = sorted(model_vals.items(), reverse=True, key=lambda item: item[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7adb29-0d33-4cd3-8954-cb80b57a9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54901f-d143-4ee4-8fdc-893fc5202d65",
   "metadata": {},
   "source": [
    "#### Performance over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c1bef-7eb4-4efc-b2e5-894be6eaf9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    for v in best_models:\n",
    "        # Organize the data\n",
    "        k = v[0]\n",
    "        df = df_map[v[0]]\n",
    "        df[['balanced_accuracy (validate)', 'balanced_accuracy (test)']] = df[['balanced_accuracy (validate)', 'balanced_accuracy (test)']].astype('float64')\n",
    "        trial_grouped = df.sort_values('trial', ascending=True).groupby('trial')\n",
    "        mean_by_trial = trial_grouped['balanced_accuracy (test)'].mean()\n",
    "        max_by_trial = trial_grouped['balanced_accuracy (test)'].max()\n",
    "        min_by_trial = trial_grouped['balanced_accuracy (test)'].min()\n",
    "        std_by_trial = trial_grouped['balanced_accuracy (test)'].std()\n",
    "    \n",
    "        from matplotlib import pyplot as plt\n",
    "    \n",
    "        # Initiate the plot\n",
    "        fig, ax = plt.subplots(1)\n",
    "        \n",
    "        # Plot the data\n",
    "        y = mean_by_trial\n",
    "        y_std = std_by_trial\n",
    "        c = \"C0\"\n",
    "        ax.plot(y, color=c)\n",
    "        upper_std = y + y_std\n",
    "        lower_std = y - y_std\n",
    "        ax.fill_between(np.arange(y.shape[0]), upper_std, lower_std, alpha=0.2, color=c)\n",
    "    \n",
    "        # Plot the max an min lines\n",
    "        ax.plot(max_by_trial, color=c, linestyle=':')\n",
    "        ax.plot(min_by_trial, color=c, linestyle=':')\n",
    "        \n",
    "        # Add axis labels\n",
    "        plt.title(k)\n",
    "        plt.xlabel('Trial')\n",
    "        plt.ylabel('Balanced Accuracy (Testing)')\n",
    "        \n",
    "        # Display the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff13081-fe93-4e6c-9688-2809b4520c61",
   "metadata": {},
   "source": [
    "#### Best/Worst Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954988a-1a09-4aa5-aa07-7ee0b424faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "correct_weights = dict()\n",
    "correct_count = dict()\n",
    "incorrect_weights = dict()\n",
    "incorrect_count = dict()\n",
    "\n",
    "for v in best_models:\n",
    "    df = df_map[v[0]]\n",
    "    w = v[1] - 0.5  # Delta from the \"naive\" performance\n",
    "    best_trials_df = df.sort_values(['balanced_accuracy (test)', 'log_loss (test)'], ascending=[True, False]).groupby('replicate').tail(1)\n",
    "    # Correctly predicted patients\n",
    "    for cst in best_trials_df['correct_samples (test)']:\n",
    "        patients = cst.replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "        for p in patients:\n",
    "            pw = correct_weights.get(p, 0)\n",
    "            pc = correct_count.get(p, 0)\n",
    "            correct_weights[p] = pw + w\n",
    "            correct_count[p] = pc + 1\n",
    "    # Incorrectly predicted patients\n",
    "    for cst in best_trials_df['incorrect_samples (test)']:\n",
    "        patients = cst.replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "        for p in patients:\n",
    "            pw = incorrect_weights.get(p, 0)\n",
    "            pc = incorrect_count.get(p, 0)\n",
    "            incorrect_weights[p] = pw + w\n",
    "            incorrect_count[p] = pc + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29770e2-21f9-4b21-85fc-13063e6ce68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_weights = dict(sorted(correct_weights.items(), key=lambda x: x[1]))\n",
    "correct_weights = {k: float(np.round(v, 3)) / correct_count[k] for k, v in correct_weights.items()}\n",
    "list(correct_weights.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6770e9-92a4-4d13-a9f5-a0480e5b8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_weights = dict(sorted(incorrect_weights.items(), key=lambda x: x[1]))\n",
    "incorrect_weights = {k: float(np.round(v, 3)) / incorrect_count[k] for k, v in incorrect_weights.items()}\n",
    "list(correct_weights.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1ddb7-cdea-4d34-ba95-3b3d34cf0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscc_df = pd.read_csv('manual_mscc.tsv', sep='\\t')\n",
    "tmp_df = pd.read_csv('mscc_c2c7_binary.tsv', sep='\\t')\n",
    "mscc_df = pd.merge(\n",
    "    mscc_df, tmp_df,\n",
    "    left_on='GRP',\n",
    "    right_on='GRP',\n",
    "    suffixes=[' [manual]', ' [automated]']\n",
    ")\n",
    "mscc_df = mscc_df.set_index('GRP')\n",
    "mscc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52967e28-34f0-445b-9197-5edb2383c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.merge(\n",
    "    mscc_df,\n",
    "    pd.DataFrame.from_dict({k: [v] for k, v in correct_weights.items()}, orient='index', columns=['avg_bacc_of_presence']),\n",
    "    left_on='GRP',\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb86a42-f262-4d86-954a-d3f038cc5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df.groupby(['acq', 'weight', 'VertLevel [manual]'])['avg_bacc_of_presence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d428d1-59e9-4fc2-9320-795ff0dbfbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df.groupby(['acq', 'weight', 'VertLevel [automated]'])['avg_bacc_of_presence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c5116-584f-4cdc-b30d-c4906f7f7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = pd.merge(\n",
    "    mscc_df,\n",
    "    pd.DataFrame.from_dict({k: [v] for k, v in incorrect_weights.items()}, orient='index', columns=['avg_bacc_of_presence']),\n",
    "    left_on='GRP',\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16630f5a-3e47-4b6a-b37e-b21d3dabdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df.groupby(['acq', 'weight', 'VertLevel [manual]'])['avg_bacc_of_presence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec1901-1da7-4513-a5a5-4c52b094121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df.groupby(['acq', 'weight', 'VertLevel [automated]'])['avg_bacc_of_presence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4db92-3c91-4c0c-a245-b0e1f6a65320",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscc_df['Protocol'] = mscc_df['acq'] + \"-\" + mscc_df['weight']\n",
    "sub_mscc_df = mscc_df.query(\"Protocol != 'unk-T1w'\")\n",
    "sub_mscc_df = sub_mscc_df.query(\"Protocol != 'axial-T1w'\")\n",
    "\n",
    "if not skip_plots:\n",
    "    sns.catplot(data=sub_mscc_df, x=\"VertLevel [manual]\", kind=\"count\", hue=\"Protocol\", order=sorted(list(set(sub_mscc_df[\"VertLevel [manual]\"]))))\n",
    "    plt.savefig(\"mscc_dist_manual.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462db860-de32-4a00-9125-d902f9134316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_plots:\n",
    "    sns.catplot(data=sub_mscc_df, x=\"VertLevel [automated]\", kind=\"count\", hue=\"Protocol\", order=sorted(list(set(sub_mscc_df[\"VertLevel [automated]\"]))))\n",
    "    plt.savefig(\"mscc_dist_automated.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180f6aa-9e81-4dc3-9fa1-e168cb49da91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
